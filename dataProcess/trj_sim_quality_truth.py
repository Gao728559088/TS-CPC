import time
import h5py 
import numpy as np
import pandas as pd
from scipy.spatial.distance import directed_hausdorff, euclidean
from fastdtw import fastdtw
from pyproj import Transformer
from tqdm import tqdm
import os

# ç»çº¬åº¦è½¬UTMï¼Œè¿”å›äºŒç»´numpyæ•°ç»„ï¼Œå•ä½ç±³
def latlon_to_utm(coords):
    transformer = Transformer.from_crs("epsg:4326", "epsg:32650", always_xy=True)
    # æ³¨æ„ä¼ å…¥é¡ºåº lon, lat
    utm_coords = np.array([transformer.transform(lon, lat) for lat, lon in coords])
    return utm_coords

# è®¡ç®—è½¨è¿¹ç©ºé—´é•¿åº¦ï¼ˆå•ä½ç±³ï¼‰
def trajectory_length(coords_utm):
    if len(coords_utm) < 2:
        return 0
    distances = np.linalg.norm(coords_utm[1:] - coords_utm[:-1], axis=1)
    return np.sum(distances)

# EDR è·ç¦»
def edr(P, Q, epsilon=10):
    n, m = len(P), len(Q)
    dp = np.zeros((n + 1, m + 1))
    for i in range(n + 1):
        dp[i][0] = i
    for j in range(m + 1):
        dp[0][j] = j
    for i in range(1, n + 1):
        for j in range(1, m + 1):
            if euclidean(P[i - 1], Q[j - 1]) <= epsilon:
                dp[i][j] = dp[i - 1][j - 1]
            else:
                dp[i][j] = min(dp[i - 1][j - 1], dp[i - 1][j], dp[i][j - 1]) + 1
    norm = min(n, m) if min(n, m) > 0 else 1
    return dp[n][m], dp[n][m] / norm

# LCSS åŒ¹é…é•¿åº¦
def lcss(P, Q, epsilon=10):
    n, m = len(P), len(Q)
    dp = np.zeros((n + 1, m + 1))
    for i in range(1, n + 1):
        for j in range(1, m + 1):
            if euclidean(P[i - 1], Q[j - 1]) <= epsilon:
                dp[i][j] = dp[i - 1][j - 1] + 1
            else:
                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])
    norm = min(n, m) if min(n, m) > 0 else 1
    return dp[n][m], dp[n][m] / norm

# FrÃ©chet è·ç¦»
def frechet_distance(P, Q):
    n, m = len(P), len(Q)
    if n == 0 or m == 0:
        return float('inf')
    ca = np.zeros((n, m))
    ca[0, 0] = np.linalg.norm(P[0] - Q[0])
    for i in range(1, n):
        ca[i, 0] = max(ca[i - 1, 0], np.linalg.norm(P[i] - Q[0]))
    for j in range(1, m):
        ca[0, j] = max(ca[0, j - 1], np.linalg.norm(P[0] - Q[j]))
    for i in range(1, n):
        for j in range(1, m):
            ca[i, j] = max(
                min(ca[i - 1, j], ca[i - 1, j - 1], ca[i, j - 1]),
                np.linalg.norm(P[i] - Q[j])
            )
    return ca[-1, -1]

def process_hdf5_trajectories(input_hdf5_path, output_excel_path, output_key_txt_path, log_path, max_len=900, max_trajs=500):
    # ç¬¬ä¸€æ­¥ï¼šå…ˆç­›é€‰è½¨è¿¹é”®ï¼Œå†™TXT
    selected_keys = []
    with h5py.File(input_hdf5_path, 'r') as f:
        for key in tqdm(f.keys(), desc="ç­›é€‰è½¨è¿¹é”®"):
            traj = f[key][()]
            if traj.shape[0] >= max_len:
                continue
            if traj.shape[0] < 4:
                continue
            selected_keys.append(key)
            if len(selected_keys) >= max_trajs:
                break

    # ä¿å­˜è½¨è¿¹é”®åTXT
    with open(output_key_txt_path, 'w') as f:
        for k in selected_keys:
            f.write(k + '\n')
    print(f"è½¨è¿¹é”®åä¿å­˜åˆ°ï¼š{output_key_txt_path}")

    # ç¬¬äºŒæ­¥ï¼šåŠ è½½é€‰ä¸­è½¨è¿¹ï¼Œè®¡ç®—æŒ‡æ ‡
    results = []
    with h5py.File(input_hdf5_path, 'r') as f:
        for key in tqdm(selected_keys, desc="è®¡ç®—è½¨è¿¹æŒ‡æ ‡"):
            traj = f[key][()]
            coords = traj[:, :2]  # [lat, lon]

            # å¥‡å¶åˆ†è½¨è¿¹
            odd = coords[::2]
            even = coords[1::2]

            odd_utm = latlon_to_utm(odd)
            even_utm = latlon_to_utm(even)
            all_utm = latlon_to_utm(coords)

            total_len = trajectory_length(all_utm)
            if total_len == 0:
                continue

            dtw_dist, _ = fastdtw(odd_utm, even_utm, dist=euclidean)
            frechet_dist = frechet_distance(odd_utm, even_utm)
            hausdorff_dist = max(
                directed_hausdorff(odd_utm, even_utm)[0],
                directed_hausdorff(even_utm, odd_utm)[0]
            )
            edr_dist, edr_norm = edr(odd_utm, even_utm, epsilon=10)
            lcss_len, lcss_norm = lcss(odd_utm, even_utm, epsilon=10)

            dtw_norm = dtw_dist / total_len
            frechet_norm = frechet_dist / total_len
            hausdorff_norm = hausdorff_dist / total_len

            results.append({
                'traj_key': key,
                'dtw': dtw_dist,
                'dtw_norm': dtw_norm,
                'frechet': frechet_dist,
                'frechet_norm': frechet_norm,
                'hausdorff': hausdorff_dist,
                'hausdorff_norm': hausdorff_norm,
                'edr': edr_dist,
                'edr_norm': edr_norm,
                'lcss': lcss_len,
                'lcss_norm': lcss_norm
            })

    # ä¿å­˜ç»“æœåˆ°Excel
    df = pd.DataFrame(results)
    df.to_excel(output_excel_path, index=False)
    print(f"å¤„ç†å®Œæ¯•ï¼Œä¿å­˜è½¨è¿¹ç›¸ä¼¼åº¦ç»“æœåˆ°ï¼š{output_excel_path}")

        # è®¡ç®—å‡å€¼
    mean_values = df[['dtw', 'dtw_norm', 'frechet', 'frechet_norm','hausdorff', 'hausdorff_norm','edr', 'edr_norm', 'lcss', 'lcss_norm']].mean()

    # è®¡ç®—æ ‡å‡†å·®
    std_values = df[['dtw', 'dtw_norm', 'frechet', 'frechet_norm','hausdorff', 'hausdorff_norm','edr', 'edr_norm', 'lcss', 'lcss_norm']].std()

    # å†™å…¥æ—¥å¿—æ–‡ä»¶
    with open(log_path, 'w', encoding='utf-8') as f:
        f.write("å„æŒ‡æ ‡åŸå§‹å€¼ä¸å½’ä¸€åŒ–å€¼çš„å‡å€¼ï¼š\n\n")
        for metric, value in mean_values.items():
            f.write(f"{metric}: {value:.4f}\n")

        f.write("\nå„æŒ‡æ ‡åŸå§‹å€¼ä¸å½’ä¸€åŒ–å€¼çš„æ ‡å‡†å·®ï¼š\n\n")
        for metric, value in std_values.items():
            f.write(f"{metric}: {value:.4f}\n")

    print(f"\nç»“æœå·²ä¿å­˜ï¼š\nExcelè¡¨æ ¼ï¼š{output_excel}\næ—¥å¿—æ–‡ä»¶ï¼š{log_path}")


def compute_statistics_from_excel(result_excel_path, log_path):
    """
    ä»ç»“æœ Excel æ–‡ä»¶ä¸­è®¡ç®—å„æŒ‡æ ‡çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œå¹¶å†™å…¥æ—¥å¿—æ–‡ä»¶ã€‚
    """
    df_result = pd.read_excel(result_excel_path)

    metrics = [
        'dtw', 'dtw_norm',
        'frechet', 'frechet_norm',
        'hausdorff', 'hausdorff_norm',
        'edr', 'edr_norm',
        'lcss', 'lcss_norm'
    ]

    # è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
    mean_values = df_result[metrics].mean()
    std_values = df_result[metrics].std()

    # å†™å…¥æ—¥å¿—
    with open(log_path, 'w', encoding='utf-8') as f:
        f.write("å„æŒ‡æ ‡åŸå§‹å€¼ä¸å½’ä¸€åŒ–å€¼çš„å‡å€¼ï¼š\n\n")
        for metric, value in mean_values.items():
            f.write(f"{metric}: {value:.4f}\n")

        f.write("\nå„æŒ‡æ ‡åŸå§‹å€¼ä¸å½’ä¸€åŒ–å€¼çš„æ ‡å‡†å·®ï¼š\n\n")
        for metric, value in std_values.items():
            f.write(f"{metric}: {value:.4f}\n")

    print(f"ğŸ“Š å‡å€¼ä¸æ ‡å‡†å·®å·²ä¿å­˜åˆ°æ—¥å¿—æ–‡ä»¶ï¼š{log_path}")



if __name__ == "__main__":
    start_time = time.time()
    input_hdf5 = "/home/ubuntu/Data/gch/CpcForTrajectory/dataset/grab_possi/grab_possi_Singapore_all/allProcessedSingapore.hdf5"
    output_excel = "/home/ubuntu/Data/gch/CpcForTrajectory/dataset/dataEnhancement/meanAndStd/trajectory_similarity_500.xlsx"
    output_key_txt = "/home/ubuntu/Data/gch/CpcForTrajectory/dataset/dataEnhancement/meanAndStd/selected_500_keys.txt"
    log_path = "/home/ubuntu/Data/gch/CpcForTrajectory/dataset/dataEnhancement/meanAndStd/trajectory_similarity_stats.txt"
    # process_hdf5_trajectories(input_hdf5, output_excel, output_key_txt,log_path)
    elapsed = time.time() - start_time
    print(f"\nâ±ï¸ è¿è¡Œæ€»æ—¶é—´: {elapsed:.2f} ç§’")

    compute_statistics_from_excel(output_excel, log_path)
